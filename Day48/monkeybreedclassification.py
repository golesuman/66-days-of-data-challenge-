# -*- coding: utf-8 -*-
"""monkeyBreedClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QhauDDEQxRMVczTbuBhxtcdk8AMB4rlD
"""

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d slothkong/10-monkey-species

! unzip 10-monkey-species.zip

import os
import cv2
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

train_path='/content/training/training'
categories=os.listdir(train_path)
categories

train_data=[]
train_label=[]
def create_training():
  for category in categories:
    path=os.path.join(train_path,category)
    class_label=categories.index(category)
    for img in os.listdir(path):
      img_array=cv2.imread(os.path.join(path,img))
      colored=cv2.cvtColor(img_array,cv2.COLOR_BGR2RGB)
      resized=cv2.resize(colored,(150,150))
      train_data.append(resized)
      train_label.append(class_label)
create_training()

def showImage(x,no_of_images):
  plt.figure(figsize=(8,8))
  for i in range(no_of_images):
    plt.subplot(no_of_images/2,2,i+1)
    plt.imshow(x[i])
  plt.show()
showImage(train_data,6)

print(len(train_label))
print(len(train_data))

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torch.utils.data import DataLoader,Dataset

class loadData(Dataset):
  def __init__(self,transform):
    self.train_data=train_data
    self.labels=train_label
    self.transform=transform

  def __getitem__(self,idx):
    images=self.train_data[idx]
    labels=self.labels[idx]
    images=self.transform(images)
    return images,labels

  def __len__(self):
    return len(self.train_data)

data_transform=transforms.Compose([transforms.ToTensor(),
                                   transforms.RandomHorizontalFlip(),
                                   transforms.RandomRotation(degrees=30),
                                   transforms.RandomResizedCrop(size=(100,100))
                                   ])
training_data=loadData(transform=data_transform)

len(training_data)
training_data[0][0].shape

train_loader=DataLoader(training_data,batch_size=32,shuffle=True)
images,labels=next(iter(train_loader))
print(images.shape)
print(len(train_loader.dataset))

test_data=[]
test_label=[]
test_path='/content/validation/validation'
def create_testing():
  for category in categories:
    t_path=os.path.join(test_path,category)
    class_label=categories.index(category)
    for img in os.listdir(t_path):
      img_arr=cv2.imread(os.path.join(t_path,img))
      colored=cv2.cvtColor(img_arr,cv2.COLOR_BGR2RGB)
      resized=cv2.resize(colored,(150,150))
      test_data.append(colored)
      test_label.append(class_label)

create_testing()

print(len(test_data))
print(len(test_label))

class loadtestData(Dataset):
  def __init__(self,transform):
    self.test_data=test_data
    self.label=test_label
    self.transform=transform

  def __getitem__(self,idx):
    images=self.test_data[idx]
    labels=self.label[idx]
    images=self.transform(images)
    return images,labels

  def __len__(self):
    return len(self.test_data)

testing_data=loadtestData(transform=data_transform)

testing_data[0]

len(testing_data)
test_loader=DataLoader(testing_data,batch_size=32,shuffle=True)

def getConvSize(H_in,W_in,conv,pool=2):
  kernel_size=conv.kernel_size
  stride=conv.stride
  padding=conv.padding
  dilation=conv.dilation
  # Ref: https://pytorch.org/docs/stable/nn.html
  H_out=np.floor((H_in+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)
  W_out=np.floor((W_in+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)
  if pool is not None:
    H_out/=pool
    W_out/=pool
    return int(H_out),int(W_out)

device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')

import torch.nn.functional as F
class NN(nn.Module):
  def __init__(self):
    super(NN,self).__init__()
    self.conv1=nn.Conv2d(in_channels=3,out_channels=10,kernel_size=2)
    h,w=getConvSize(100,100,self.conv1,pool=2)
    self.conv2=nn.Conv2d(in_channels=10,out_channels=20,kernel_size=2)
    h,w=getConvSize(h,w,self.conv2,pool=2)
    self.conv3=nn.Conv2d(in_channels=20,out_channels=40,kernel_size=2)
    h,w=getConvSize(h,w,self.conv3,pool=2)
    self.conv4=nn.Conv2d(in_channels=40,out_channels=60,kernel_size=2)
    h,w=getConvSize(h,w,self.conv4,pool=2)
    self.flatten=h*w*60
    self.l1=nn.Linear(self.flatten,40)
    self.l2=nn.Linear(40,10)

  def forward(self,x):
    x=F.relu(self.conv1(x))
    x=F.max_pool2d(x,2,2)
    x=F.relu(self.conv2(x))
    x=F.max_pool2d(x,2,2)
    x=F.relu(self.conv3(x))
    x=F.max_pool2d(x,2,2)
    x=F.relu(self.conv4(x))
    x=F.max_pool2d(x,2,2)
    x=x.view(-1,self.flatten)
    x=F.relu(self.l1(x))
    x=F.softmax(self.l2(x))
    return x

model=NN().to(device)
criterion=nn.CrossEntropyLoss()
optimizer=torch.optim.Adam(model.parameters(),lr=0.001)

size = len(train_loader.dataset)
def train_loop(dataloader, model, loss_fn, optimizer):
  size = len(train_loader.dataset)
  for i, (images,labels) in enumerate(train_loader):
    images=images.to(device)
    labels=labels.to(device)

    #forward pass
    outputs=model(images)
    loss=criterion(outputs,labels)

    # backward
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if (i+1)%32 == 0:
      print(f'Epoch {epoch+1}/{epochs}, step {i+1}/{size},loss={loss.item():.4f}')

  

def test_loop(dataloader, model, loss_fn):
 with torch.no_grad():
  n_correct=0
  n_samples=0
  for images,labels in test_loader:
    images=images.to(device)
    labels=labels.to(device)
    outputs=model(images)
  # value,index
    _,predictions=torch.max(outputs,1)

    n_samples+=labels.shape[0]
    n_correct+=(predictions==labels).sum().item()
  acc=100.0 * n_correct / n_samples
  print(f'accuracy={acc}')

epochs = 15
for epoch in range(epochs):
    print(f"Epoch {epoch+1}\n-------------------------------")
    train_loop(train_loader, model, criterion, optimizer)
    test_loop(test_loader, model, criterion)
print("Done!")

