# -*- coding: utf-8 -*-
"""simplegan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h1FMZ3a7oNuYz3axWc51CiG78fAJNSHn
"""

import torch
import torch.nn as nn
import torchvision.datasets as datasets
import torchvision.transforms as transform
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import torchvision

class Discriminator(nn.Module):
  def __init__(self,image_dim):
    super().__init__()
    self.disc=nn.Sequential(
                            nn.Linear(image_dim,128),
                            nn.LeakyReLU(0.1),
                            nn.Linear(128,1),
                            nn.Sigmoid()
                            )
class Generator(nn.Module):
  def __init__(self,z_dim,img_dim):
    super().__init__()
    self.gen=nn.Sequential(
        nn.Linear(z_dim,256),
        nn.LeakyReLU(0.1),
        nn.Linear(256,img_dim),
        nn.Tanh(),
    )

  def forward(self,x):
    return self.gen(x)

# hyperparameter
device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
lr=0.0003
z_dim=64
batch_size=32
num_epochs=50
image_dim=64

disc=Discriminator(image_dim).to(device)
gen=Generator(z_dim,image_dim).to(device)
fixed_noise=torch.randn((batch_size,z_dim)).to(device)
transforms=transform.Compose(
    [
     transform.ToTensor(),
     transform.Normalize((0.1307,),(0.3081))
    ]
)

dataset=datasets.MNIST(root='dataset/',transform=transform,download=True)

loader=DataLoader(dataset,batch_size=batch_size,shuffle=True)

opt_disc=optim.Adam(disc.parameters(),lr=lr)
opt_gen=optim.Adam(gen.parameters(),lr=lr)
criterion=nn.BCELoss()
writer_fake=SummaryWriter(f'runs/GAN_MNIST/fake')
writer_real=SummaryWriter(f'runs/GAN_MNIST/real')
step=0

for epoch in range(num_epochs):
  for batch_idx,(real,_) in enumerate(loader):
    real=real.view(-1,784).to(device)
    batch_size=real.shape[0]
    noise=torch.randn(batch_size,z_dim).to(device)
    fake=gen(noise)
    disc_real=disc(real).view(-1)
    lossD_real=criterion(disc_real,torch.ones_like(disc_real))
    disc_fake=disc(fake).view(-1)
    lossD_fake=criterion(disc_fake,torch.zeros_like(disc_fake))
    lossD=(lossD_real+lossD_fake)/2
    disc.zero_grad()
    lossD.backward(retain_graph=True)
    opt_disc.step()

    # Train Generator min log(1-D(G(z)))  <--> max log(D(G(z)))
    output=disc(fake).view(-1)
    lossG=criterion(output,torch.ones_like(output))
    gen.zero_grad()
    lossG.backward()
    opt_gen.step()

    if batch_idx==0:
      pritn(f'Epoch[{epoch}/{num_epochs}] Loss D:{lossD:.4f}, Loss G:{lossG:.4f}')
      with torch.no_grad():
        fake=gen(fixed_noise).reshape(-1,1,28,28)
        data=real.reshape(-1,1,28,28)
        img_grid_fake=torchvision.utils.make_grid(fake,normalize=True)
        img_grid_real=torchvision.utils.make_grid(data,normalize=True)
        
        writer_fake.add_image(
            "Mnist fake Images",img_grid_fake,global_step=step

        )
        writer_real.add_image(
            "Mnist real Images",img_grid_real,global_step=step
        )
        step+=1

