# -*- coding: utf-8 -*-
"""NeuralStyleTransfer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H0j09GeMnJp0x0jDZCTNajKst-hGaO4r
"""

import torch.nn as nn
import torch
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.utils import save_image
from PIL import Image

model=models.vgg19(pretrained=True).features

device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
loader=transforms.Compose([
                           transforms.Resize((500,500)),
                           transforms.ToTensor(),
])
class VGG(nn.Module):
  def __init__(self):
    super(VGG,self).__init__()
    self.chosen_features=['0','5','10','19','28']
    self.model=models.vgg19(pretrained=True).features[:29]

  def forward(self,x):
    features=[]
    for layer_num,layer in enumerate(self.model):
      x=layer(x)

      if str(layer_num) in self.chosen_features:
        features.append(x)
    return features


def load_image(image_name):
  image=Image.open(image_name)
  image=loader(image).unsqueeze(0)
  return image.to(device)

original_image=load_image('/content/anne.jpeg')
style_image=load_image('/content/paint.jpeg')

generated=original_image.clone().requires_grad_(True)
total_steps=6000
learning_rate=0.001
alpha=1
beta=0.01
model=VGG().to(device).eval()
optimizer=optim.Adam([generated],lr=learning_rate)
for step in range(total_steps):
  generated_features=model(generated)
  original_features=model(original_image)
  style_features=model(style_image)

  style_loss=original_loss=0
  for gen_feat,original_feat,style_feat in zip(generated_features,original_features,style_features):
    batch_size,channel,height,width=gen_feat.shape
    original_loss+=torch.mean((gen_feat-original_feat)**2)
    # compute the gram metric
    G=gen_feat.view(channel,height*width).mm(gen_feat.view(channel,height*width).t()
    )
    A=style_feat.view(channel,height*width).mm(style_feat.view(channel,height*width).t()
    )
    style_loss+=torch.mean((G-A)**2)


  total_loss=alpha*original_loss+beta*style_loss
  optimizer.zero_grad()
  total_loss.backward()
  optimizer.step()
  if step%200==0:
    print(total_loss)
    save_image(generated,"generated.png")

